<!DOCTYPE html><html lang="en-GB"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="theme-color" content="#ff8c00"><title>Tokenization is the mother of NLP</title><meta name="description" content="About the importance of tokenization in NLP."><base href="http://gu.illau.me/posts/tokenization-is-the-mother-of-nlp/" target="_top"><link href="/css/main.css" rel="stylesheet"><script src="/js/analytics.js" defer async></script><script src="/js/ui.js" defer async></script><link href="/manifest.webmanifest" rel="manifest"><link href="http://feeds.feedburner.com/just-a-blog" rel="alternate" type="application/rss+xml" title="A blog by G.C. Marty"><link href="/favicon.ico" rel="shortcut icon" type="image/x-icon"></head><body><nav><h1 class="name"><a href="/">A blog<small> by G.C. Marty</small></a></h1><div style="display:none" class="menu icon-menu"></div><ul class="nav-links"><li class="text-link"><a href="/about.html">about</a></li><li class="text-link"><a href="/apps.html">apps</a></li><li class="text-link"><a href="/talks.html">talks</a></li><li class="text-link"><a href="/posts.html">posts</a></li></ul><div class="social-media"><a href="https://github.com/gmarty" class="icon-github"></a><a href="https://twitter.com/g_marty" class="icon-twitter"></a></div></nav><div class="content"><div class="post-head group"><a href="/posts/tokenization-is-the-mother-of-nlp/"><h1 class="post-title">Tokenization is the mother of NLP</h1></a><span class="post-date">2012/09/17</span><span class="post-reading-time"></span></div><div class="post-body markdown"><p>I recently started contributing to <a href="https://github.com/NaturalNode/natural">natural, a set of <strong>natural language processing</strong> tools (NLP) in JavaScript for node.js</a>. Here&#39;s what I learned from this.</p>
<p><a href="http://en.wikipedia.org/wiki/Tokenization">Words tokenization</a> is a critical part of natural language processing. This is often neglected because it sounds so easy. You just need to split a string on spaces.
And that is enough... for most of the languages. However some languages don&#39;t actually use space to separate words, like Japanese or Chinese.
I was lucky enough to find out that there is <a href="http://chasen.org/~taku/software/TinySegmenter/">a tokenizer in JavaScript for Japanese by Kudo Taku</a>. The license allowed me to use it on natural. I&#39;m fully satisfied: no dictionary to maintain and no heavy tools to develop! It is using a statistical model to determine where to cut tokens. And it turned out to be quite efficient given its light weight.</p>
<p>The only sentence that failed to be tokenized properly is the famous “すもももももももものうち。” (that can be written &quot;李も桃も桃のうち。&quot; meaning &quot;plums and peaches are both types of peach&quot;). But this one is a bit tricky.</p>
<p>Now that we can tokenize Japanese, we can also:</p>
<ul>
<li>Remove stop words</li>
<li>Stem tokens</li>
<li>Compute N-grams</li>
</ul>
<p>I wanted to extend one of my previous NLP project to Japanese, but couldn&#39;t find a tokenizer at the time (it was developed in PHP). So I reluctantly discarded this idea. I hope I&#39;ll be able to help natural enough so that such decisions won&#39;t have to be taken in the future.</p>
<p>As a side note, there are also many tokenizers for Chinese out there in several programming languages. I will have to check their licenses on my spare time to see if they are compatible with that of natural. But I&#39;m not sure how to benchmark their respective accuracies as I don&#39;t speak Chinese :-(</p>
</div><div class="social"><a href="https://twitter.com/share" class="twitter-share-button">Tweet</a><div data-size="medium" data-annotation="bubble" data-width="300" class="g-plusone"></div><a href="http://news.ycombinator.com/submit" class="hn-share-button">Vote on HN</a></div><div id="comments"><div id="disqus_thread"></div></div><script>// Hacker News
(function(d, t) {
  var g = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
  g.src = '//hnbutton.appspot.com/static/hn.min.js';
  s.parentNode.insertBefore(g, s);
}(document, 'script'));

// Twitter
!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="https://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");

// Google Plus
(function() {
  var po = document.createElement('script'); po.async = true;
  po.src = 'https://apis.google.com/js/plusone.js';
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
})();

// Disqus
var disqus_shortname = 'gmarty';
(function() {
    var dsq = document.createElement('script'); dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script></div></body></html>